{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [default]","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"},"colab":{"name":"script.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Jmc41i47RiSc","colab_type":"text"},"source":["### 1. Import Necessary Libraries"]},{"cell_type":"code","metadata":{"id":"Tw3SjTBlOTCb","colab_type":"code","colab":{}},"source":["import sys\n","import nltk\n","import sklearn\n","import pandas\n","import numpy\n","\n","print('Python: {}'.format(sys.version))\n","print('NLTK: {}'.format(nltk.__version__))\n","print('Scikit-learn: {}'.format(sklearn.__version__))\n","print('Pandas: {}'.format(pandas.__version__))\n","print('Numpy: {}'.format(numpy.__version__))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KytXwdtPOTCg","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","\n","# load the dataset of SMS messages\n","df = pd.read_table('../dataset/SMSSpamCollection', header=None, encoding='utf-8')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkGFhPrxOTCj","colab_type":"code","colab":{}},"source":["# print useful information about the dataset\n","print(df.info())\n","print(df.head())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKxc9yxsOTCl","colab_type":"code","colab":{}},"source":["# check class distribution\n","classes = df[0]\n","print(classes.value_counts())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bNGhPxckOTCo","colab_type":"text"},"source":["### 2. Preprocess the Data\n"]},{"cell_type":"code","metadata":{"id":"kNLlXRwEOTCo","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# convert class labels to binary values, 0 = ham and 1 = spam\n","encoder = LabelEncoder()\n","Y = encoder.fit_transform(classes)\n","\n","print(Y[:10])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4GQVU6ZOTCq","colab_type":"code","colab":{}},"source":["# store the SMS message data\n","text_messages = df[1]\n","print(text_messages[:10])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ER7icYxhOTCt","colab_type":"text"},"source":["#### 2.1 Regular Expressions"]},{"cell_type":"code","metadata":{"id":"daqombAtOTCt","colab_type":"code","colab":{}},"source":["# use regular expressions to replace email addresses, URLs, phone numbers, other numbers\n","\n","# Replace email addresses with 'email'\n","processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n","                                 'emailaddress')\n","\n","# Replace URLs with 'webaddress'\n","processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n","                                  'webaddress')\n","\n","# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n","processed = processed.str.replace(r'£|\\$', 'moneysymb')\n","    \n","# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n","processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n","                                  'phonenumbr')\n","    \n","# Replace numbers with 'numbr'\n","processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXE7cK_cOTCw","colab_type":"code","colab":{}},"source":["# Remove punctuation\n","processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n","\n","# Replace whitespace between terms with a single space\n","processed = processed.str.replace(r'\\s+', ' ')\n","\n","# Remove leading and trailing whitespace\n","processed = processed.str.replace(r'^\\s+|\\s+?$', '')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLUtKg1-OTCy","colab_type":"code","colab":{}},"source":["# change words to lower case - Hello, HELLO, hello are all the same word\n","processed = processed.str.lower()\n","print(processed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pkrqj-aTOTC0","colab_type":"code","colab":{}},"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","# remove stop words from text messages\n","\n","stop_words = set(stopwords.words('english'))\n","\n","processed = processed.apply(lambda x: ' '.join(\n","    term for term in x.split() if term not in stop_words))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"we2PnHMVOTC2","colab_type":"code","colab":{}},"source":["# Remove word stems using a Porter stemmer\n","ps = nltk.PorterStemmer()\n","\n","processed = processed.apply(lambda x: ' '.join(\n","    ps.stem(term) for term in x.split()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6QtyCtJvOTC4","colab_type":"text"},"source":["### 3. Generating Features"]},{"cell_type":"code","metadata":{"id":"nckX0RJdOTC4","colab_type":"code","colab":{}},"source":["nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","# create bag-of-words\n","all_words = []\n","\n","for message in processed:\n","    words = word_tokenize(message)\n","    for w in words:\n","        all_words.append(w)\n","        \n","all_words = nltk.FreqDist(all_words)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJ-Z-H1POTC9","colab_type":"code","colab":{}},"source":["# print the total number of words and the 15 most common words\n","print('Number of words: {}'.format(len(all_words)))\n","print('Most common words: {}'.format(all_words.most_common(15)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDuQhUcwOTC_","colab_type":"code","colab":{}},"source":["# use the 1500 most common words as features\n","word_features = list(all_words.keys())[:1500]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sRWOEpypOTDC","colab_type":"code","colab":{}},"source":["# The find_features function will determine which of the 1500 word features are contained in the review\n","def find_features(message):\n","    words = word_tokenize(message)\n","    features = {}\n","    for word in word_features:\n","        features[word] = (word in words)\n","\n","    return features\n","\n","# Lets see an example!\n","features = find_features(processed[0])\n","for key, value in features.items():\n","    if value == True:\n","        print key"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbjAci96OTDE","colab_type":"code","colab":{}},"source":["# Now lets do it for all the messages\n","messages = zip(processed, Y)\n","\n","# define a seed for reproducibility\n","seed = 1\n","np.random.seed = seed\n","np.random.shuffle(messages)\n","\n","# call find_features function for each SMS message\n","featuresets = [(find_features(text), label) for (text, label) in messages]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q79qO2VnOTDG","colab_type":"code","colab":{}},"source":["# we can split the featuresets into training and testing datasets using sklearn\n","from sklearn import model_selection\n","\n","# split the data into training and testing datasets\n","training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CRI57LdOTDI","colab_type":"code","colab":{}},"source":["print(len(training))\n","print(len(testing))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9wYdI1sZOTDK","colab_type":"text"},"source":["### 4. Scikit-Learn Classifiers with NLTK"]},{"cell_type":"code","metadata":{"id":"KlESRwBkOTDK","colab_type":"code","colab":{}},"source":["# We can use sklearn algorithms in NLTK\n","from nltk.classify.scikitlearn import SklearnClassifier\n","from sklearn.svm import SVC\n","\n","model = SklearnClassifier(SVC(kernel = 'linear'))\n","\n","# train the model on the training data\n","model.train(training)\n","\n","# and test on the testing dataset!\n","accuracy = nltk.classify.accuracy(model, testing)*100\n","print(\"SVC Accuracy: {}\".format(accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvxCHs0JOTDM","colab_type":"code","colab":{}},"source":["from nltk.classify.scikitlearn import SklearnClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","\n","# Define models to train\n","names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n","         \"Naive Bayes\", \"SVM Linear\"]\n","\n","classifiers = [\n","    KNeighborsClassifier(),\n","    DecisionTreeClassifier(),\n","    RandomForestClassifier(),\n","    LogisticRegression(),\n","    SGDClassifier(max_iter = 100),\n","    MultinomialNB(),\n","    SVC(kernel = 'linear')\n","]\n","\n","models = zip(names, classifiers)\n","\n","for name, model in models:\n","    nltk_model = SklearnClassifier(model)\n","    nltk_model.train(training)\n","    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n","    print(\"{} Accuracy: {}\".format(name, accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6csMqpFOTDO","colab_type":"code","colab":{}},"source":["# Ensemble methods - Voting classifier\n","from sklearn.ensemble import VotingClassifier\n","\n","names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n","         \"Naive Bayes\", \"SVM Linear\"]\n","\n","classifiers = [\n","    KNeighborsClassifier(),\n","    DecisionTreeClassifier(),\n","    RandomForestClassifier(),\n","    LogisticRegression(),\n","    SGDClassifier(max_iter = 100),\n","    MultinomialNB(),\n","    SVC(kernel = 'linear')\n","]\n","\n","models = zip(names, classifiers)\n","\n","nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n","nltk_ensemble.train(training)\n","accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n","print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2q4FQYIDOTDQ","colab_type":"code","colab":{}},"source":["# make class label prediction for testing set\n","txt_features, labels = zip(*testing)\n","\n","prediction = nltk_ensemble.classify_many(txt_features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I1hJ5LOXOTDS","colab_type":"code","colab":{}},"source":["# print a confusion matrix and a classification report\n","print(classification_report(labels, prediction))\n","\n","pd.DataFrame(\n","    confusion_matrix(labels, prediction),\n","    index = [['actual', 'actual'], ['ham', 'spam']],\n","    columns = [['predicted', 'predicted'], ['ham', 'spam']])"],"execution_count":0,"outputs":[]}]}